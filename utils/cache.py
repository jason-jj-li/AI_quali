# -*- coding: utf-8 -*-
"""
QualInsight ç¼“å­˜è£…é¥°å™¨æ¨¡å—
æä¾›æ™ºèƒ½ç¼“å­˜åŠŸèƒ½ï¼Œæå‡LLMè°ƒç”¨æ€§èƒ½
"""

import functools
import hashlib
import json
import time
from typing import Callable, Any, Optional, Dict
from functools import wraps


# ==================== ç¼“å­˜é…ç½® ====================

DEFAULT_CACHE_TTL = 3600  # é»˜è®¤ç¼“å­˜1å°æ—¶
CACHE_VERSION = "v1"  # ç¼“å­˜ç‰ˆæœ¬å·


# ==================== ç®€å•çš„å†…å­˜ç¼“å­˜ ====================

class SimpleCache:
    """ç®€å•çš„å†…å­˜ç¼“å­˜å®ç°"""

    def __init__(self):
        self._cache: Dict[str, tuple] = {}  # key: (value, expire_time)
        self._stats = {
            'hits': 0,
            'misses': 0,
            'sets': 0
        }

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        if key in self._cache:
            value, expire_time = self._cache[key]
            if expire_time is None or time.time() < expire_time:
                self._stats['hits'] += 1
                return value
            else:
                # ç¼“å­˜è¿‡æœŸ
                del self._cache[key]
        self._stats['misses'] += 1
        return None

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """è®¾ç½®ç¼“å­˜å€¼"""
        expire_time = time.time() + ttl if ttl else None
        self._cache[key] = (value, expire_time)
        self._stats['sets'] += 1

    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()

    def get_stats(self) -> Dict[str, int]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self._stats['hits'] + self._stats['misses']
        hit_rate = self._stats['hits'] / total if total > 0 else 0
        return {
            **self._stats,
            'size': len(self._cache),
            'hit_rate': hit_rate
        }


# å…¨å±€ç¼“å­˜å®ä¾‹
_global_cache = SimpleCache()


# ==================== ç¼“å­˜é”®ç”Ÿæˆ ====================

def generate_cache_key(func_name: str, args: tuple, kwargs: dict) -> str:
    """
    ç”Ÿæˆç¼“å­˜é”®

    Args:
        func_name: å‡½æ•°å
        args: ä½ç½®å‚æ•°
        kwargs: å…³é”®å­—å‚æ•°

    Returns:
        ç¼“å­˜é”®
    """
    # åºåˆ—åŒ–å‚æ•°
    key_parts = [
        CACHE_VERSION,
        func_name,
    ]

    # æ·»åŠ ä½ç½®å‚æ•°ï¼ˆæ’é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼‰
    for arg in args:
        if _is_json_serializable(arg):
            key_parts.append(json.dumps(arg, sort_keys=True, ensure_ascii=False))
        else:
            # å¯¹äºä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œä½¿ç”¨å…¶ç±»å‹å’ŒID
            key_parts.append(f"{type(arg).__name__}_{id(arg)}")

    # æ·»åŠ å…³é”®å­—å‚æ•°
    if kwargs:
        sorted_kwargs = sorted(kwargs.items())
        for k, v in sorted_kwargs:
            if _is_json_serializable(v):
                key_parts.append(f"{k}:{json.dumps(v, sort_keys=True, ensure_ascii=False)}")
            else:
                key_parts.append(f"{k}:{type(v).__name__}_{id(v)}")

    # ç”Ÿæˆå“ˆå¸Œ
    key_string = "|".join(key_parts)
    return hashlib.md5(key_string.encode()).hexdigest()


def _is_json_serializable(obj: Any) -> bool:
    """æ£€æŸ¥å¯¹è±¡æ˜¯å¦å¯ä»¥JSONåºåˆ—åŒ–"""
    try:
        json.dumps(obj)
        return True
    except (TypeError, ValueError):
        return False


# ==================== ç¼“å­˜è£…é¥°å™¨ ====================

def cached(
    ttl: int = DEFAULT_CACHE_TTL,
    key_func: Optional[Callable] = None,
    cache_instance: Optional[SimpleCache] = None
) -> Callable:
    """
    ç¼“å­˜è£…é¥°å™¨

    Args:
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
        key_func: è‡ªå®šä¹‰ç¼“å­˜é”®ç”Ÿæˆå‡½æ•°
        cache_instance: è‡ªå®šä¹‰ç¼“å­˜å®ä¾‹

    Returns:
        è£…é¥°åçš„å‡½æ•°

    Example:
        @cached(ttl=1800)
        def expensive_operation(param1, param2):
            return result
    """
    cache = cache_instance or _global_cache

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if key_func:
                cache_key = key_func(func.__name__, args, kwargs)
            else:
                cache_key = generate_cache_key(func.__name__, args, kwargs)

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_value = cache.get(cache_key)
            if cached_value is not None:
                return cached_value

            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # å­˜å…¥ç¼“å­˜
            cache.set(cache_key, result, ttl)

            return result

        # æ·»åŠ ç¼“å­˜ç›¸å…³æ–¹æ³•
        wrapper.cache_clear = lambda: cache.clear()
        wrapper.cache_stats = lambda: cache.get_stats()

        return wrapper

    return decorator


def cached_llm(ttl: int = 3600) -> Callable:
    """
    LLMè°ƒç”¨ä¸“ç”¨ç¼“å­˜è£…é¥°å™¨

    Args:
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        è£…é¥°åçš„å‡½æ•°

    Example:
        @cached_llm(ttl=1800)
        def call_llm(prompt, model="gpt-3.5"):
            return response
    """
    return cached(ttl=ttl, cache_instance=_global_cache)


def cached_llm_with_key(key_func: Callable) -> Callable:
    """
    LLMè°ƒç”¨ä¸“ç”¨ç¼“å­˜è£…é¥°å™¨ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é”®ï¼‰

    Args:
        key_func: è‡ªå®šä¹‰ç¼“å­˜é”®ç”Ÿæˆå‡½æ•°

    Returns:
        è£…é¥°åçš„å‡½æ•°

    Example:
        def make_key(prompt, model):
            return f"{model}:{hashlib.md5(prompt.encode()).hexdigest()}"

        @cached_llm_with_key(make_key)
        def call_llm(prompt, model):
            return response
    """
    return cached(key_func=key_func, cache_instance=_global_cache)


# ==================== æ¡ä»¶ç¼“å­˜è£…é¥°å™¨ ====================

def cached_if(condition: Callable[[...], bool], ttl: int = DEFAULT_CACHE_TTL) -> Callable:
    """
    æ¡ä»¶ç¼“å­˜è£…é¥°å™¨ - ä»…åœ¨æ¡ä»¶æ»¡è¶³æ—¶ç¼“å­˜

    Args:
        condition: æ¡ä»¶å‡½æ•°ï¼Œæ¥å—åŸå‡½æ•°å‚æ•°
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

    Returns:
        è£…é¥°åçš„å‡½æ•°

    Example:
        @cached_if(lambda prompt: len(prompt) > 100)
        def call_llm(prompt):
            return response
    """
    cache = _global_cache

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # æ£€æŸ¥æ¡ä»¶
            if not condition(*args, **kwargs):
                return func(*args, **kwargs)

            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = generate_cache_key(func.__name__, args, kwargs)

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_value = cache.get(cache_key)
            if cached_value is not None:
                return cached_value

            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # å­˜å…¥ç¼“å­˜
            cache.set(cache_key, result, ttl)

            return result

        return wrapper

    return decorator


# ==================== ç¼“å­˜ç®¡ç† ====================

def clear_cache() -> None:
    """æ¸…ç©ºå…¨å±€ç¼“å­˜"""
    _global_cache.clear()


def get_cache_stats() -> Dict[str, int]:
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    return _global_cache.get_stats()


def display_cache_stats() -> str:
    """ç”Ÿæˆå¯è¯»çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    stats = get_cache_stats()
    total = stats['hits'] + stats['misses']

    return (
        f"ç¼“å­˜ç»Ÿè®¡:\n"
        f"  å‘½ä¸­: {stats['hits']}\n"
        f"  æœªå‘½ä¸­: {stats['misses']}\n"
        f"  å‘½ä¸­ç‡: {stats['hit_rate']:.1%}\n"
        f"  ç¼“å­˜é¡¹: {stats['size']}"
    )


# ==================== Streamlit é›†æˆ ====================

def show_cache_stats():
    """åœ¨ Streamlit ä¸­æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡"""
    stats = get_cache_stats()

    st.markdown("### ğŸ“Š ç¼“å­˜æ€§èƒ½")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("å‘½ä¸­", stats['hits'])
    with col2:
        st.metric("æœªå‘½ä¸­", stats['misses'])
    with col3:
        st.metric("å‘½ä¸­ç‡", f"{stats['hit_rate']:.1%}")
    with col4:
        st.metric("ç¼“å­˜é¡¹", stats['size'])

    # æ¸…é™¤æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºç¼“å­˜"):
        clear_cache()
        st.success("âœ… ç¼“å­˜å·²æ¸…ç©º")
        st.rerun()


# ==================== è¾…åŠ©å‡½æ•° ====================

def make_hash_key(*args, **kwargs) -> str:
    """
    ä»å‚æ•°åˆ›å»ºå“ˆå¸Œé”®

    Returns:
        MD5å“ˆå¸Œå­—ç¬¦ä¸²
    """
    key_parts = []

    for arg in args:
        if _is_json_serializable(arg):
            key_parts.append(json.dumps(arg, sort_keys=True))
        else:
            key_parts.append(str(arg))

    for k, v in sorted(kwargs.items()):
        if _is_json_serializable(v):
            key_parts.append(f"{k}:{json.dumps(v, sort_keys=True)}")
        else:
            key_parts.append(f"{k}:{str(v)}")

    key_string = "|".join(key_parts)
    return hashlib.md5(key_string.encode()).hexdigest()


# ==================== æ‰¹é‡æ“ä½œç¼“å­˜ ====================

def batch_cached(ttl: int = DEFAULT_CACHE_TTL) -> Callable:
    """
    æ‰¹é‡æ“ä½œç¼“å­˜è£…é¥°å™¨

    å¯¹äºåˆ—è¡¨/æ•°ç»„ç±»å‹çš„ç»“æœï¼Œç¼“å­˜æ¯ä¸ªé¡¹ç›®

    Args:
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

    Returns:
        è£…é¥°åçš„å‡½æ•°
    """
    cache = _global_cache

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # å°è¯•ä»ç¼“å­˜è·å–
            cache_key = generate_cache_key(func.__name__, args, kwargs)
            cached_value = cache.get(cache_key)

            if cached_value is not None:
                return cached_value

            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # å­˜å…¥ç¼“å­˜
            cache.set(cache_key, result, ttl)

            return result

        return wrapper

    return decorator
