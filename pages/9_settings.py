# -*- coding: utf-8 -*-
"""
QualInsight Settings Page
è®¾ç½®é¡µé¢
"""

import streamlit as st
from i18n import t, render_language_switch


def render_settings():
    """
    æ¸²æŸ“è®¾ç½®é¡µé¢

    åŠŸèƒ½ï¼š
    - LLM é…ç½®
    - API å¯†é’¥ç®¡ç†
    - è¯­è¨€è®¾ç½®
    - è°ƒè¯•æ¨¡å¼
    - ä½¿ç”¨å¸®åŠ©
    """
    st.title(f"âš™ï¸ {t('settings.title')}")

    # LLM é…ç½®
    st.subheader(t('settings.llm_config.title'))

    provider = st.selectbox(
        t('settings.llm_config.provider'),
        ["lm_studio", "openai", "deepseek", "anthropic"],
        index=["lm_studio", "openai", "deepseek", "anthropic"].index(
            st.session_state.get('llm_provider', 'lm_studio')
        )
    )

    st.session_state.llm_provider = provider

    if provider == "lm_studio":
        _render_lm_studio_config()
    elif provider == "openai":
        _render_openai_config()
    elif provider == "deepseek":
        _render_deepseek_config()
    elif provider == "anthropic":
        _render_anthropic_config()

    st.divider()

    # å…¶ä»–è®¾ç½®
    col1, col2 = st.columns(2)

    with col1:
        st.subheader(t('settings.language.title'))
        render_language_switch()

    with col2:
        st.subheader(t('settings.advanced.title'))
        debug_mode = st.checkbox(
            t('settings.advanced.debug_mode'),
            value=st.session_state.get('debug_mode', False)
        )
        st.session_state.debug_mode = debug_mode

    st.divider()

    # ä½¿ç”¨å¸®åŠ©
    st.subheader(t('settings.help.title'))
    _render_help()


def _render_lm_studio_config():
    """æ¸²æŸ“ LM Studio é…ç½®"""
    st.info(t('settings.llm_config.lm_studio.help'))

    base_url = st.text_input(
        t('settings.llm_config.base_url'),
        value=st.session_state.get('llm_base_url', 'http://localhost:1234/v1')
    )
    st.session_state.llm_base_url = base_url

    model = st.text_input(
        t('settings.llm_config.model'),
        value=st.session_state.get('llm_model', 'qwen/qwen3-next-80b')
    )
    st.session_state.llm_model = model


def _render_openai_config():
    """æ¸²æŸ“ OpenAI é…ç½®"""
    api_key = st.text_input(
        t('settings.llm_config.api_key'),
        type="password",
        value=st.session_state.get('llm_api_key', '')
    )
    st.session_state.llm_api_key = api_key

    model = st.selectbox(
        t('settings.llm_config.model'),
        ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
        index=["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"].index(
            st.session_state.get('llm_model', 'gpt-4o-mini')
        )
    )
    st.session_state.llm_model = model


def _render_deepseek_config():
    """æ¸²æŸ“ Deepseek é…ç½®"""
    api_key = st.text_input(
        t('settings.llm_config.api_key'),
        type="password",
        value=st.session_state.get('llm_api_key', '')
    )
    st.session_state.llm_api_key = api_key

    model = st.selectbox(
        t('settings.llm_config.model'),
        ["deepseek-chat", "deepseek-coder"],
        index=["deepseek-chat", "deepseek-coder"].index(
            st.session_state.get('llm_model', 'deepseek-chat')
        )
    )
    st.session_state.llm_model = model


def _render_anthropic_config():
    """æ¸²æŸ“ Anthropic é…ç½®"""
    api_key = st.text_input(
        t('settings.llm_config.api_key'),
        type="password",
        value=st.session_state.get('llm_api_key', '')
    )
    st.session_state.llm_api_key = api_key

    model = st.selectbox(
        t('settings.llm_config.model'),
        ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
        index=["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"].index(
            st.session_state.get('llm_model', 'claude-3-5-sonnet-20241022')
        )
    )
    st.session_state.llm_model = model


def _render_help():
    """æ¸²æŸ“ä½¿ç”¨å¸®åŠ©"""
    with st.expander(t('settings.help.workflow'), expanded=False):
        st.markdown("""
        ### ğŸ“‹ å·¥ä½œæµç¨‹

        1. **æ•°æ®å‡†å¤‡** â†’ è¾“å…¥ç ”ç©¶é—®é¢˜å’Œæ–‡æœ¬
        2. **AIç¼–ç ** â†’ é€‰æ‹©ç¼–ç æ¨¡å¼ï¼Œå¼€å§‹ç¼–ç 
        3. **ä¸»é¢˜åˆ†æ** â†’ ä»ç¼–ç ä¸­è¯†åˆ«ä¸»é¢˜
        4. **å¯è§†åŒ–** â†’ æŸ¥çœ‹åˆ†æç»“æœå›¾è¡¨
        5. **æŠ¥å‘Šç”Ÿæˆ** â†’ ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š
        6. **å¯¼å‡ºä¸‹è½½** â†’ å¯¼å‡ºæ•°æ®å’Œç»“æœ
        """)

    with st.expander(t('settings.help.llm'), expanded=False):
        st.markdown("""
        ### ğŸ¤– LLM é…ç½®

        - **LM Studio**: æœ¬åœ°æ¨¡å‹ï¼Œéœ€å…ˆå¯åŠ¨ LM Studio
        - **OpenAI**: éœ€è¦æœ‰æ•ˆ API å¯†é’¥
        - **Deepseek**: éœ€è¦æœ‰æ•ˆ API å¯†é’¥
        - **Anthropic**: éœ€è¦æœ‰æ•ˆ API å¯†é’¥

        **æ¨è**: å­¦ä¹ é˜¶æ®µä½¿ç”¨ LM Studioï¼Œæ­£å¼ç ”ç©¶ä½¿ç”¨ GPT-4o
        """)

    with st.expander(t('settings.help.tips'), expanded=False):
        st.markdown("""
        ### ğŸ’¡ ä½¿ç”¨æŠ€å·§

        - å®šæœŸä½¿ç”¨ã€Œå¯¼å‡ºä¸‹è½½ã€ä¿å­˜å·¥ä½œ
        - ç¼–ç æ—¶å…ˆä½¿ç”¨å½’çº³å¼ï¼Œå†å»ºç«‹å±‚çº§ç»“æ„
        - ä¸»é¢˜åˆ†æå»ºè®®å¤šæ¬¡è¿­ä»£ä¼˜åŒ–
        - ä½¿ç”¨ç¼“å­˜å¯ä»¥åŠ é€Ÿé‡å¤æ“ä½œ
        """)
